@unpublished{alsallakh2020,
  title = {Mind the {{Pad}} -- {{CNNs}} Can {{Develop Blind Spots}}},
  author = {Alsallakh, Bilal and Kokhlikyan, Narine and Miglani, Vivek and Yuan, Jun and Reblitz-Richardson, Orion},
  date = {2020-10-05},
  eprint = {2010.02178},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2010.02178},
  urldate = {2022-02-11},
  abstract = {We show how feature maps in convolutional networks are susceptible to spatial bias. Due to a combination of architectural choices, the activation at certain locations is systematically elevated or weakened. The major source of this bias is the padding mechanism. Depending on several aspects of convolution arithmetic, this mechanism can apply the padding unevenly, leading to asymmetries in the learned weights. We demonstrate how such bias can be detrimental to certain tasks such as small object detection: the activation is suppressed if the stimulus lies in the impacted area, leading to blind spots and misdetection. We propose solutions to mitigate spatial bias and demonstrate how they can improve model accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\alsallakhMindPadCNNs2020.pdf;C\:\\Users\\mario\\Zotero\\storage\\9YET63DI\\2010.html}
}

@article{amato2013,
  title = {Artificial Neural Networks in Medical Diagnosis},
  author = {Amato, Filippo and López, Alberto and Peña-Méndez, Eladia María and Vaňhara, Petr and Hampl, Aleš and Havel, Josef},
  date = {2013-07-31},
  journaltitle = {Journal of Applied Biomedicine},
  shortjournal = {J Appl Biomed},
  volume = {11},
  number = {2},
  pages = {47--58},
  issn = {1214021X, 12140287},
  doi = {10.2478/v10136-012-0031-x},
  url = {http://jab.zsf.jcu.cz/doi/10.2478/v10136-012-0031-x.html},
  urldate = {2022-02-04},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\amatoArtificialNeuralNetworks2013.pdf}
}

@inproceedings{andricEffectClassDistribution2016,
  title = {The Effect of Class Distribution on Classification Algorithms in Credit Risk Assessment},
  booktitle = {2016 39th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Andric, K. and Kalpic, D.},
  date = {2016-05},
  pages = {1241--1247},
  publisher = {{IEEE}},
  location = {{Opatija, Croatia}},
  doi = {10.1109/MIPRO.2016.7522329},
  url = {http://ieeexplore.ieee.org/document/7522329/},
  urldate = {2023-02-08},
  eventtitle = {2016 39th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  isbn = {978-953-233-086-1}
}

@incollection{arganda-carreras2017,
  title = {Designing {{Image Analysis Pipelines}} in {{Light Microscopy}}: {{A Rational Approach}}},
  shorttitle = {Designing {{Image Analysis Pipelines}} in {{Light Microscopy}}},
  booktitle = {Light {{Microscopy}}},
  author = {Arganda-Carreras, Ignacio and Andrey, Philippe},
  editor = {Markaki, Yolanda and Harz, Hartmann},
  date = {2017},
  series = {Methods in {{Molecular Biology}}},
  volume = {1563},
  pages = {185--207},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4939-6810-7_13},
  url = {http://link.springer.com/10.1007/978-1-4939-6810-7_13},
  urldate = {2022-01-21},
  abstract = {With the progress of microscopy techniques and the rapidly growing amounts of acquired imaging data, there is an increased need for automated image processing and analysis solutions in biological studies. Each new application requires the design of a specific image analysis pipeline, by assembling a series of image processing operations. Many commercial or free bioimage analysis software are now available and several textbooks and reviews have presented the mathematical and computational fundamentals of image processing and analysis. Tens, if not hundreds, of algorithms and methods have been developed and integrated into image analysis software, resulting in a combinatorial explosion of possible image processing sequences. This paper presents a general guideline methodology to rationally address the design of image processing and analysis pipelines. The originality of the proposed approach is to follow an iterative, backwards procedure from the target objectives of analysis. The proposed goal-oriented strategy should help biologists to better apprehend image analysis in the context of their research and should allow them to efficiently interact with image processing specialists.},
  isbn = {978-1-4939-6808-4 978-1-4939-6810-7},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\arganda-carrerasDesigningImageAnalysis2017.pdf}
}

@article{barrandon1987,
  title = {Three Clonal Types of Keratinocyte with Different Capacities for Multiplication.},
  author = {Barrandon, Y. and Green, H.},
  date = {1987-04-01},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {84},
  number = {8},
  pages = {2302--2306},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.84.8.2302},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.84.8.2302},
  urldate = {2022-01-25},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\barrandonThreeClonalTypes1987.pdf}
}

@article{beaver2014,
  title = {Clonogenicity: {{Holoclones}} and {{Meroclones Contain Stem Cells}}},
  shorttitle = {Clonogenicity},
  author = {Beaver, Charlotte M. and Ahmed, Aamir and Masters, John R.},
  editor = {Nie, Daotai},
  date = {2014-02-26},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS ONE},
  volume = {9},
  number = {2},
  pages = {e89834},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0089834},
  url = {https://dx.plos.org/10.1371/journal.pone.0089834},
  urldate = {2022-01-25},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\beaverClonogenicityHoloclonesMeroclones2014.pdf}
}

@article{belkin2019,
  title = {Reconciling Modern Machine-Learning Practice and the Classical Bias–Variance Trade-Off},
  author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  date = {2019-08-06},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {116},
  number = {32},
  pages = {15849--15854},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1903070116},
  url = {https://pnas.org/doi/full/10.1073/pnas.1903070116},
  urldate = {2023-01-18},
  abstract = {Significance             While breakthroughs in machine learning and artificial intelligence are changing society, our fundamental understanding has lagged behind. It is traditionally believed that fitting models to the training data exactly is to be avoided as it leads to poor performance on unseen data. However, powerful modern classifiers frequently have near-perfect fit in training, a disconnect that spurred recent intensive research and controversy on whether theory provides practical insights. In this work, we show how classical theory and modern practice can be reconciled within a single unified performance curve and propose a mechanism underlying its emergence. We believe this previously unknown pattern connecting the structure and performance of learning architectures will help shape design and understanding of learning algorithms.           ,              Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias–variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias–variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This “double-descent” curve subsumes the textbook U-shaped bias–variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\belkinReconcilingModernMachinelearning2019.pdf}
}

@article{biEmpiricalComparisonStateoftheart2018,
  title = {An Empirical Comparison on State-of-the-Art Multi-Class Imbalance Learning Algorithms and a New Diversified Ensemble Learning Scheme},
  author = {Bi, Jingjun and Zhang, Chongsheng},
  date = {2018-10},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {158},
  pages = {81--93},
  issn = {09507051},
  doi = {10.1016/j.knosys.2018.05.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S095070511830282X},
  urldate = {2023-02-08},
  langid = {english}
}

@article{briscoe2011,
  title = {Conceptual Complexity and the Bias/Variance Tradeoff},
  author = {Briscoe, Erica and Feldman, Jacob},
  date = {2011-01},
  journaltitle = {Cognition},
  shortjournal = {Cognition},
  volume = {118},
  number = {1},
  pages = {2--16},
  issn = {00100277},
  doi = {10.1016/j.cognition.2010.10.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027710002295},
  urldate = {2023-01-18},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\briscoeConceptualComplexityBias2011.pdf}
}

@article{caicedo2017,
  title = {Data-Analysis Strategies for Image-Based Cell Profiling},
  author = {Caicedo, Juan C and Cooper, Sam and Heigwer, Florian and Warchal, Scott and Qiu, Peng and Molnar, Csaba and Vasilevich, Aliaksei S and Barry, Joseph D and Bansal, Harmanjit Singh and Kraus, Oren and Wawer, Mathias and Paavolainen, Lassi and Herrmann, Markus D and Rohban, Mohammad and Hung, Jane and Hennig, Holger and Concannon, John and Smith, Ian and Clemons, Paul A and Singh, Shantanu and Rees, Paul and Horvath, Peter and Linington, Roger G and Carpenter, Anne E},
  date = {2017-09},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {14},
  number = {9},
  pages = {849--863},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.4397},
  url = {http://www.nature.com/articles/nmeth.4397},
  urldate = {2022-01-31},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\caicedoDataanalysisStrategiesImagebased2017.pdf}
}

@article{chawlaEditorialSpecialIssue2004,
  title = {Editorial: Special Issue on Learning from Imbalanced Data Sets},
  shorttitle = {Editorial},
  author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
  date = {2004-06},
  journaltitle = {ACM SIGKDD Explorations Newsletter},
  shortjournal = {SIGKDD Explor. Newsl.},
  volume = {6},
  number = {1},
  pages = {1--6},
  issn = {1931-0145, 1931-0153},
  doi = {10.1145/1007730.1007733},
  url = {https://dl.acm.org/doi/10.1145/1007730.1007733},
  urldate = {2023-02-08},
  langid = {english}
}

@article{chen2021,
  title = {Potentials of {{AI}} in Medical Image Analysis in {{Gastroenterology}} and {{Hepatology}}},
  author = {Chen, Hao and Sung, Joseph J Y},
  date = {2021-01},
  journaltitle = {Journal of Gastroenterology and Hepatology},
  shortjournal = {Journal of Gastroenterology and Hepatology},
  volume = {36},
  number = {1},
  pages = {31--38},
  issn = {0815-9319, 1440-1746},
  doi = {10.1111/jgh.15327},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/jgh.15327},
  urldate = {2022-01-21},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\chenPotentialsAIMedical2021.pdf}
}

@misc{cholletKeras2015,
  title = {Keras},
  author = {Chollet, François and others},
  date = {2015},
  url = {https://keras.io}
}

@article{chowdharySegmentationFeatureExtraction2020,
  title = {Segmentation and {{Feature Extraction}} in {{Medical Imaging}}: {{A Systematic Review}}},
  shorttitle = {Segmentation and {{Feature Extraction}} in {{Medical Imaging}}},
  author = {Chowdhary, Chiranji Lal and Acharjya, D.P.},
  date = {2020},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {167},
  pages = {26--36},
  issn = {18770509},
  doi = {10.1016/j.procs.2020.03.179},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S187705092030644X},
  urldate = {2022-02-04},
  langid = {english}
}

@article{debruijne2016,
  title = {Machine Learning Approaches in Medical Image Analysis: {{From}} Detection to Diagnosis},
  shorttitle = {Machine Learning Approaches in Medical Image Analysis},
  author = {de Bruijne, Marleen},
  options = {useprefix=true},
  date = {2016-10},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {33},
  pages = {94--97},
  issn = {13618415},
  doi = {10.1016/j.media.2016.06.032},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841516301098},
  urldate = {2022-02-01},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\debruijneMachineLearningApproaches2016.pdf}
}

@article{dietterich1995,
  title = {Overfitting and Undercomputing in Machine Learning},
  author = {Dietterich, Tom},
  date = {1995-09},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {27},
  number = {3},
  pages = {326--327},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/212094.212114},
  url = {https://dl.acm.org/doi/10.1145/212094.212114},
  urldate = {2023-01-17},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\dietterichOverfittingUndercomputingMachine1995.pdf}
}

@article{du2019,
  title = {Automatic Classification of Cells in Microscopic Fecal Images Using Convolutional Neural Networks},
  author = {Du, Xiaohui and Liu, Lin and Wang, Xiangzhou and Ni, Guangming and Zhang, Jing and {hao}, Ruqian and Liu, Juanxiu and Liu, Yong},
  date = {2019-04-30},
  journaltitle = {Bioscience Reports},
  volume = {39},
  number = {4},
  pages = {BSR20182100},
  issn = {0144-8463, 1573-4935},
  doi = {10.1042/BSR20182100},
  url = {https://portlandpress.com/bioscirep/article/39/4/BSR20182100/110851/Automatic-classification-of-cells-in-microscopic},
  urldate = {2022-01-21},
  abstract = {Abstract             The analysis of fecal-type components for clinical diagnosis is important. The main examination involves the counting of red blood cells (RBCs), white blood cells (WBCs), and molds under the microscopic. With the development of machine vision, some vision-based detection schemes have been proposed. However, these methods have a single target for detection, with low detection efficiency and low accuracy. We proposed an algorithm to identify the visible image of fecal composition based on intelligent deep learning. The algorithm mainly includes region proposal and candidate recognition. In the process of segmentation, we proposed a morphology extraction algorithm in a complex background. As for the candidate recognition, we proposed a new convolutional neural network (CNN) architecture based on Inception-v3 and principal component analysis (PCA). This method achieves high-average Precision of 90.7\%, which is better than the other mainstream CNN models. Finally, the images within the rectangle marks were obtained. The total time for detection of an image was roughly 1200 ms. The algorithm proposed in the present paper can be integrated into an automatic fecal detection system.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\duAutomaticClassificationCells2019.pdf}
}

@inproceedings{ebrahimWillTransferLearning2019,
  title = {Will {{Transfer Learning Enhance ImageNet Classification Accuracy Using ImageNet-Pretrained Models}}?},
  booktitle = {2019 10th {{International Conference}} on {{Information}} and {{Communication Systems}} ({{ICICS}})},
  author = {Ebrahim, Maad and Al-Ayyoub, Mahmoud and Alsmirat, Mohammad A.},
  date = {2019-06},
  pages = {211--216},
  publisher = {{IEEE}},
  location = {{Irbid, Jordan}},
  doi = {10.1109/IACS.2019.8809114},
  url = {https://ieeexplore.ieee.org/document/8809114/},
  urldate = {2022-02-10},
  eventtitle = {2019 10th {{International Conference}} on {{Information}} and {{Communication Systems}} ({{ICICS}})},
  isbn = {978-1-72810-045-6}
}

@incollection{freilingWandelVomIndustriellen2002,
  title = {Der Wandel vom industriellen Produkt- zum Diensleistungsgeschäft — dargestellt am Beispiel der Umsetzung von Betreibermodellen im mitteleuropäischen Maschinenbau},
  booktitle = {Neue Entwicklungen im Dienstleistungsmarketing},
  author = {Freiling, Jörg},
  editor = {Mühlbacher, Hans and Thelen, Eva},
  date = {2002},
  pages = {203--222},
  publisher = {{Deutscher Universitätsverlag}},
  location = {{Wiesbaden}},
  doi = {10.1007/978-3-322-97830-1_8},
  url = {http://link.springer.com/10.1007/978-3-322-97830-1_8},
  urldate = {2022-02-10},
  isbn = {978-3-8244-7608-4 978-3-322-97830-1},
  langid = {ngerman}
}

@article{galarReviewEnsemblesClass2012,
  title = {A {{Review}} on {{Ensembles}} for the {{Class Imbalance Problem}}: {{Bagging-}}, {{Boosting-}}, and {{Hybrid-Based Approaches}}},
  shorttitle = {A {{Review}} on {{Ensembles}} for the {{Class Imbalance Problem}}},
  author = {Galar, M. and Fernandez, A. and Barrenechea, E. and Bustince, H. and Herrera, F.},
  date = {2012-07},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  shortjournal = {IEEE Trans. Syst., Man, Cybern. C},
  volume = {42},
  number = {4},
  pages = {463--484},
  issn = {1094-6977, 1558-2442},
  doi = {10.1109/TSMCC.2011.2161285},
  url = {http://ieeexplore.ieee.org/document/5978225/},
  urldate = {2023-02-08}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-03561-3},
  pagetotal = {775},
  keywords = {Machine learning}
}

@article{guo2020,
  title = {Review {{Sharing}} via {{Deep Semi-Supervised Code Clone Detection}}},
  author = {Guo, Chenkai and Yang, Hui and Huang, Dengrong and Zhang, Jianwen and Dong, Naipeng and Xu, Jing and Zhu, Jingwen},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {24948--24965},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2966532},
  url = {https://ieeexplore.ieee.org/document/8959206/},
  urldate = {2022-01-21},
  abstract = {Code review as a typical type of user feedback has recently drawn increasing attentions for improving code quality. To carry out research on code review, sufficient review data is normally required. As a result, recent efforts commonly focus on analysis for projects with sufficient reviews (called ‘‘sprojects’’), rather than projects with extremely few ones (called ‘‘f-projects’’). Actually, through statistics on public platforms, the latter ones dominate open source software, in which novel approaches should be explored to improve their review-based code improvement. In this paper, we try to address the problem via building a review sharing channel where the informative review can be reasonably delivered from s-projects to the f-projects. To ensure the accuracy of shared reviews, we introduce a novel code clone detection model based on Convolutional Neural Network (CNN), and build suitable ‘‘s-projects, f-projects’’ pairs through the clone detection. Especially, to alleviate the dataset heterogeneity between the training and testing, an autoencoder-based semi-supervised learning strategy is employed. Furthermore, to improve the sharing experience, heuristic filtering tactics are applied to reduce the time cost. Meanwhile, the LDA (Latent Dirichlet Allocation)-based ranking algorithm is used for presenting diverse review themes. We have implemented the sharing channel as a prototype system RSharer+, which contains three representative modules: data preprocessing, code clone detection and review presentation. The collected datasets are first transformed into context-sensitive numerical vectors in the data proprecessing. Then in the clone detection, data vectors are trained and tested on the BigCloneBench and real code-review pairs. At last, the presentation module provides review classification and theme extraction for better sharing experience. Extensive comparative experiments on hundreds of real labelled code fragments demonstrate the precision of clone detection and the effectiveness of review sharing.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\guoReviewSharingDeep2020.pdf}
}

@article{haarnojaSoftActorCriticOffPolicy2018,
  title = {Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  shorttitle = {Soft {{Actor-Critic}}},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  date = {2018},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1801.01290},
  url = {https://arxiv.org/abs/1801.01290},
  urldate = {2023-01-31},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@article{haghofer2020,
  title = {Evolutionary Optimization of Image Processing for Cell Detection in Microscopy Images},
  author = {Haghofer, Andreas and Dorl, Sebastian and Oszwald, Andre and Breuss, Johannes and Jacak, Jaroslaw and Winkler, Stephan M.},
  date = {2020-12},
  journaltitle = {Soft Computing},
  shortjournal = {Soft Comput},
  volume = {24},
  number = {23},
  pages = {17847--17862},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-020-05033-0},
  url = {https://link.springer.com/10.1007/s00500-020-05033-0},
  urldate = {2022-01-21},
  abstract = {In this paper, we present a new evolution-based algorithm that optimizes cell detection image processing workflows in a self-adaptive fashion. We use evolution strategies to optimize the parameters for all steps of the image processing pipeline and improve cell detection results. The algorithm reliably produces good cell detection results without the need for extensive domain knowledge. Our algorithm also needs no labeled data to produce good cell detection results compared to the state-ofthe-art neural network approaches. Furthermore, the algorithm can easily be adapted to different applications by modifying the processing steps in the pipeline and has high scalability since it supports multithreading and computation on graphical processing units (GPUs).},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\haghoferEvolutionaryOptimizationImage2020.pdf}
}

@article{haiboheLearningImbalancedData2009,
  title = {Learning from {{Imbalanced Data}}},
  author = {{Haibo He} and Garcia, E.A.},
  date = {2009-09},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {21},
  number = {9},
  pages = {1263--1284},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2008.239},
  url = {http://ieeexplore.ieee.org/document/5128907/},
  urldate = {2023-02-08}
}

@article{haixiangLearningClassimbalancedData2017,
  title = {Learning from Class-Imbalanced Data: {{Review}} of Methods and Applications},
  shorttitle = {Learning from Class-Imbalanced Data},
  author = {Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
  date = {2017-05},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {73},
  pages = {220--239},
  issn = {09574174},
  doi = {10.1016/j.eswa.2016.12.035},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417416307175},
  urldate = {2023-02-08},
  langid = {english}
}

@unpublished{han2021,
  title = {Pre-{{Trained Models}}: {{Past}}, {{Present}} and {{Future}}},
  shorttitle = {Pre-{{Trained Models}}},
  author = {Han, Xu and Zhang, Zhengyan and Ding, Ning and Gu, Yuxian and Liu, Xiao and Huo, Yuqi and Qiu, Jiezhong and Yao, Yuan and Zhang, Ao and Zhang, Liang and Han, Wentao and Huang, Minlie and Jin, Qin and Lan, Yanyan and Liu, Yang and Liu, Zhiyuan and Lu, Zhiwu and Qiu, Xipeng and Song, Ruihua and Tang, Jie and Wen, Ji-Rong and Yuan, Jinhui and Zhao, Wayne Xin and Zhu, Jun},
  date = {2021-08-11},
  eprint = {2106.07139},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2106.07139},
  urldate = {2022-02-10},
  abstract = {Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success and become a milestone in the field of artificial intelligence (AI). Owing to sophisticated pre-training objectives and huge model parameters, large-scale PTMs can effectively capture knowledge from massive labeled and unlabeled data. By storing knowledge into huge parameters and fine-tuning on specific tasks, the rich knowledge implicitly encoded in huge parameters can benefit a variety of downstream tasks, which has been extensively demonstrated via experimental verification and empirical analysis. It is now the consensus of the AI community to adopt PTMs as backbone for downstream tasks rather than learning models from scratch. In this paper, we take a deep look into the history of pre-training, especially its special relation with transfer learning and self-supervised learning, to reveal the crucial position of PTMs in the AI development spectrum. Further, we comprehensively review the latest breakthroughs of PTMs. These breakthroughs are driven by the surge of computational power and the increasing availability of data, towards four important directions: designing effective architectures, utilizing rich contexts, improving computational efficiency, and conducting interpretation and theoretical analysis. Finally, we discuss a series of open problems and research directions of PTMs, and hope our view can inspire and advance the future study of PTMs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\hanPreTrainedModelsPresent2021.pdf;C\:\\Users\\mario\\Zotero\\storage\\JKBTP6LE\\2106.html}
}

@article{harahap2020,
  title = {Implementation of {{Convolutional Neural Network}} in the Classification of Red Blood Cells Have Affected of Malaria},
  author = {Harahap, Mawaddah and Jefferson, Jefferson and Barti, Surya and Samosir, Suprianto and Turnip, Christi Andika},
  date = {2020-04-01},
  journaltitle = {SinkrOn},
  shortjournal = {SinkrOn},
  volume = {5},
  number = {2},
  pages = {199--207},
  issn = {2541-2019, 2541-044X},
  doi = {10.33395/sinkron.v5i2.10713},
  url = {https://jurnal.polgan.ac.id/index.php/sinkron/article/view/10713},
  urldate = {2022-01-21},
  abstract = {Malaria is a disease caused by plasmodium which attacks red blood cells. Diagnosis of malaria can be made by examining the patient's red blood cells using a microscope. Convolutional Neural Network (CNN) is a deep learning method that is growing rapidly. CNN is often used in image classification. The CNN process usually requires considerable resources. This is one of the weaknesses of CNN. In this study, the CNN architecture used in the classification of red blood cell images is LeNet-5 and DRNet. The data used is a segmented image of red blood cells and is secondary data. Before conducting the data training, data pre-processing and data augmentation from the dataset was carried out. The number of layers of the LeNet-5 and DRNet models were 4 and 7. The test accuracy of the LeNet-5 and DrNet models was 95\% and 97.3\%, respectively. From the test results, it was found that the LeNet-5 model was more suitable in terms of red blood cell classification. By using the LeNet-5 architecture, the resources used to perform classification can be reduced compared to previous studies where the accuracy obtained is also the same because the number of layers is less, which is only 4 layers.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\harahapImplementationConvolutionalNeural2020.pdf}
}

@unpublished{he2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2022-02-10},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\heDeepResidualLearning2015.pdf;C\:\\Users\\mario\\Zotero\\storage\\6ATU9AP7\\1512.html}
}

@unpublished{he2020,
  title = {Deeply-{{Supervised Density Regression}} for {{Automatic Cell Counting}} in {{Microscopy Images}}},
  author = {He, Shenghua and Minn, Kyaw Thu and Solnica-Krezel, Lilianna and Anastasio, Mark A. and Li, Hua},
  date = {2020-11-09},
  eprint = {2011.03683},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2011.03683},
  urldate = {2022-01-21},
  abstract = {Accurately counting the number of cells in microscopy images is required in many medical diagnosis and biological studies. This task is tedious, timeconsuming, and prone to subjective errors. However, designing automatic counting methods remains challenging due to low image contrast, complex background, large variance in cell shapes and counts, and significant cell occlusions in two-dimensional microscopy images. In this study, we proposed a new density regression-based method for automatically counting cells in microscopy images. The proposed method processes two innovations compared to other state-ofthe-art density regression-based methods. First, the density regression model (DRM) is designed as a concatenated fully convolutional regression network (C-FCRN) to employ multi-scale image features for the estimation of cell density maps from given images. Second, auxiliary convolutional neural networks (AuxCNNs) are employed to assist in the training of intermediate layers of the designed C-FCRN to improve the DRM performance on unseen datasets. Experimental studies evaluated on four datasets demonstrate the superior performance of the proposed method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\heDeeplySupervisedDensityRegression2020.pdf}
}

@article{heo2017,
  title = {Real-Time {{Image Processing}} for {{Microscopy-based Label-free Imaging Flow Cytometry}} in a {{Microfluidic Chip}}},
  author = {Heo, Young Jin and Lee, Donghyeon and Kang, Junsu and Lee, Keondo and Chung, Wan Kyun},
  date = {2017-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {7},
  number = {1},
  pages = {11651},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-11534-0},
  url = {http://www.nature.com/articles/s41598-017-11534-0},
  urldate = {2022-01-21},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\heoRealtimeImageProcessing2017.pdf}
}

@article{hirsch2017,
  title = {Regeneration of the Entire Human Epidermis Using Transgenic Stem Cells},
  author = {Hirsch, Tobias and Rothoeft, Tobias and Teig, Norbert and Bauer, Johann W. and Pellegrini, Graziella and De Rosa, Laura and Scaglione, Davide and Reichelt, Julia and Klausegger, Alfred and Kneisz, Daniela and Romano, Oriana and Secone Seconetti, Alessia and Contin, Roberta and Enzo, Elena and Jurman, Irena and Carulli, Sonia and Jacobsen, Frank and Luecke, Thomas and Lehnhardt, Marcus and Fischer, Meike and Kueckelhaus, Maximilian and Quaglino, Daniela and Morgante, Michele and Bicciato, Silvio and Bondanza, Sergio and De Luca, Michele},
  date = {2017-11},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {551},
  number = {7680},
  pages = {327--332},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature24487},
  url = {http://www.nature.com/articles/nature24487},
  urldate = {2022-01-21},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\hirschRegenerationEntireHuman2017.pdf}
}

@article{hu2016,
  title = {The Distance Function Effect on K-Nearest Neighbor Classification for Medical Datasets},
  author = {Hu, Li-Yu and Huang, Min-Wei and Ke, Shih-Wen and Tsai, Chih-Fong},
  date = {2016-12},
  journaltitle = {SpringerPlus},
  shortjournal = {SpringerPlus},
  volume = {5},
  number = {1},
  pages = {1304},
  issn = {2193-1801},
  doi = {10.1186/s40064-016-2941-7},
  url = {http://springerplus.springeropen.com/articles/10.1186/s40064-016-2941-7},
  urldate = {2022-01-25},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\huDistanceFunctionEffect2016.pdf}
}

@inproceedings{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  editor = {Bach, Francis and Blei, David},
  date = {2015-07-07},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {37},
  pages = {448--456},
  publisher = {{PMLR}},
  location = {{Lille, France}},
  url = {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
}

@article{jacquemet2021,
  title = {Deep Learning to Analyse Microscopy Images},
  author = {Jacquemet, Guillaume},
  date = {2021-10-01},
  journaltitle = {The Biochemist},
  volume = {43},
  number = {5},
  pages = {60--64},
  issn = {0954-982X, 1740-1194},
  doi = {10.1042/bio_2021_167},
  url = {https://portlandpress.com/biochemist/article/43/5/60/229698/Deep-learning-to-analyse-microscopy-images},
  urldate = {2022-01-21},
  abstract = {Artificial intelligence (AI)-powered algorithms are now influencing many aspects of our day-to-day life, from providing movies/music recommendations to controlling self-driving cars. These algorithms are also increasingly used in the lab to aid biomedical research. In particular, the ability to analyse and process images using AI is slowly revolutionizing the quality and quantity of data we collect from microscopy images. In fact, AI-based algorithms can now be applied to perform virtually any high-performance image analysis tasks such as classifying images, detecting and segmenting objects, aligning images or improving image quality by removing noise or increasing image resolution. This short feature article briefly underlies the principles behind using AI algorithms to analyse microscopy images with a specific focus on segmentation and denoising.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\jacquemetDeepLearningAnalyse2021.pdf}
}

@article{janocha2017,
  title = {On {{Loss Functions}} for {{Deep Neural Networks}} in {{Classification}}},
  author = {Janocha, Katarzyna and Czarnecki, Wojciech Marian},
  date = {2017},
  journaltitle = {Schedae Informaticae},
  shortjournal = {SI},
  volume = {1/2016},
  issn = {20838476},
  doi = {10.4467/20838476SI.16.004.6185},
  url = {https://www.ejournals.eu/Schedae-Informaticae/2016/Volume-25/art/9009/},
  urldate = {2022-02-04},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\janochaLossFunctionsDeep2017.pdf}
}

@misc{juliani2020,
  title = {Unity: {{A General Platform}} for {{Intelligent Agents}}},
  shorttitle = {Unity},
  author = {Juliani, Arthur and Berges, Vincent-Pierre and Teng, Ervin and Cohen, Andrew and Harper, Jonathan and Elion, Chris and Goy, Chris and Gao, Yuan and Henry, Hunter and Mattar, Marwan and Lange, Danny},
  date = {2020-05-06},
  number = {arXiv:1809.02627},
  eprint = {1809.02627},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1809.02627},
  urldate = {2023-01-25},
  abstract = {Recent advances in artificial intelligence have been driven by the presence of increasingly realistic and complex simulated environments. However, many of the existing environments provide either unrealistic visuals, inaccurate physics, low task complexity, restricted agent perspective, or a limited capacity for interaction among artificial agents. Furthermore, many platforms lack the ability to flexibly configure the simulation, making the simulated environment a black-box from the perspective of the learning system. In this work, we propose a novel taxonomy of existing simulation platforms and discuss the highest level class of general platforms which enable the development of learning environments that are rich in visual, physical, task, and social complexity. We argue that modern game engines are uniquely suited to act as general platforms and as a case study examine the Unity engine and open source Unity ML-Agents Toolkit. We then survey the research enabled by Unity and the Unity ML-Agents Toolkit, discussing the kinds of research a flexible, interactive and easily configurable general platform can facilitate.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\julianiUnityGeneralPlatform2020.pdf;C\:\\Users\\mario\\Zotero\\storage\\LISI8E2Q\\1809.html}
}

@article{kasper-eulaers2021,
  title = {Short {{Communication}}: {{Detecting Heavy Goods Vehicles}} in {{Rest Areas}} in {{Winter Conditions Using YOLOv5}}},
  shorttitle = {Short {{Communication}}},
  author = {Kasper-Eulaers, Margrit and Hahn, Nico and Berger, Stian and Sebulonsen, Tom and Myrland, Øystein and Kummervold, Per Egil},
  date = {2021-03-31},
  journaltitle = {Algorithms},
  shortjournal = {Algorithms},
  volume = {14},
  number = {4},
  pages = {114},
  issn = {1999-4893},
  doi = {10.3390/a14040114},
  url = {https://www.mdpi.com/1999-4893/14/4/114},
  urldate = {2022-02-15},
  abstract = {The proper planning of rest periods in response to the availability of parking spaces at rest areas is an important issue for haulage companies as well as traffic and road administrations. We present a case study of how You Only Look Once (YOLO)v5 can be implemented to detect heavy goods vehicles at rest areas during winter to allow for the real-time prediction of parking spot occupancy. Snowy conditions and the polar night in winter typically pose some challenges for image recognition, hence we use thermal network cameras. As these images typically have a high number of overlaps and cut-offs of vehicles, we applied transfer learning to YOLOv5 to investigate whether the front cabin and the rear are suitable features for heavy goods vehicle recognition. Our results show that the trained algorithm can detect the front cabin of heavy goods vehicles with high confidence, while detecting the rear seems more difficult, especially when located far away from the camera. In conclusion, we firstly show an improvement in detecting heavy goods vehicles using their front and rear instead of the whole vehicle, when winter conditions result in challenging images with a high number of overlaps and cut-offs, and secondly, we show thermal network imaging to be promising in vehicle detection.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\kasper-eulaersShortCommunicationDetecting2021.pdf}
}

@article{kaurThresholdingMethodsLesion2017,
  title = {Thresholding Methods for Lesion Segmentation of Basal Cell Carcinoma in Dermoscopy Images},
  author = {Kaur, R. and LeAnder, R. and Mishra, N. K. and Hagerty, J. R. and Kasmi, R. and Stanley, R. J. and Celebi, M. E. and Stoecker, W. V.},
  date = {2017-08},
  journaltitle = {Skin Research and Technology},
  shortjournal = {Skin Res Technol},
  volume = {23},
  number = {3},
  pages = {416--428},
  issn = {0909752X},
  doi = {10.1111/srt.12352},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/srt.12352},
  urldate = {2022-02-20},
  langid = {english}
}

@article{kim2020,
  title = {Phenotypic {{Heterogeneity}} and {{Plasticity}} of {{Cancer Cell Migration}} in a {{Pancreatic Tumor Three-Dimensional Culture Model}}},
  author = {Kim, Seul-Ki and Jang, So Dam and Kim, Hyunho and Chung, Seok and Park, Jong Kook and Kuh, Hyo-Jeong},
  date = {2020-05-21},
  journaltitle = {Cancers},
  shortjournal = {Cancers},
  volume = {12},
  number = {5},
  pages = {1305},
  issn = {2072-6694},
  doi = {10.3390/cancers12051305},
  url = {https://www.mdpi.com/2072-6694/12/5/1305},
  urldate = {2022-02-08},
  abstract = {Invasive cancer cell migration is a key feature of metastatic human pancreatic ductal adenocarcinoma (PDAC), yet the underlying mechanisms remain poorly understood. Here, we investigated modes of cancer cell invasion using two pancreatic cancer cell lines with differential epithelial–mesenchymal status, PANC-1 and BxPC-3, under 3D culture conditions. Multicellular tumor spheroids (TSs) were grown in a collagen matrix co-cultured with pancreatic stellate cells (PSCs) using microchannel chips. PANC-1 cells showed individual migration from TSs via invadopodium formation. BxPC-3 cells showed plasticity between collective and individual migration in either mesenchymal mode, with filopodium-like protrusions, or blebby amoeboid mode. These two cell lines showed significantly different patterns of extracellular matrix (ECM) remodeling, with MMP-dependent degradation in a limited area of ECM around invadopodia for PANC-1 cells, or MMP-independent extensive deformation of ECM for BxPC-3 cells. Cancer cell migration out of the collagen channel significantly increased by PSCs and directional cancer cell migration was mediated by fibronectin deposited by PSCs. Our results highlight the phenotypic heterogeneity and plasticity of PDAC cell migration and ECM remodeling under 3D culture conditions. This 3D co-culture model of pancreatic cancer cells and PSCs offers a useful tool for studying cancer cell migration and ECM remodeling to identify and develop potential molecular targets and anti-cancer agents against human PDAC.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\kimPhenotypicHeterogeneityPlasticity2020.pdf}
}

@article{knaack2018,
  title = {Liver Metastasis of Pancreatic Cancer: The Hepatic Microenvironment Impacts Differentiation and Self-Renewal Capacity of Pancreatic Ductal Epithelial Cells},
  shorttitle = {Liver Metastasis of Pancreatic Cancer},
  author = {Knaack, Hendrike and Lenk, Lennart and Philipp, Lisa-Marie and Miarka, Lauritz and Rahn, Sascha and Viol, Fabrice and Hauser, Charlotte and Egberts, Jan-Hendrik and Gundlach, Jan-Paul and Will, Olga and Tiwari, Sanjay and Mikulits, Wolfgang and Schumacher, Udo and Hengstler, Jan G. and Sebens, Susanne},
  date = {2018-08-03},
  journaltitle = {Oncotarget},
  shortjournal = {Oncotarget},
  volume = {9},
  number = {60},
  pages = {31771--31786},
  issn = {1949-2553},
  doi = {10.18632/oncotarget.25884},
  url = {https://www.oncotarget.com/lookup/doi/10.18632/oncotarget.25884},
  urldate = {2022-02-08},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\knaackLiverMetastasisPancreatic2018.pdf}
}

@article{kondaOnActorCriticAlgorithms2003,
  title = {{{OnActor-Critic Algorithms}}},
  author = {Konda, Vijay R. and Tsitsiklis, John N.},
  date = {2003-01},
  journaltitle = {SIAM Journal on Control and Optimization},
  shortjournal = {SIAM J. Control Optim.},
  volume = {42},
  number = {4},
  pages = {1143--1166},
  issn = {0363-0129, 1095-7138},
  doi = {10.1137/S0363012901385691},
  url = {http://epubs.siam.org/doi/10.1137/S0363012901385691},
  urldate = {2023-01-25},
  langid = {english}
}

@article{krawczyk2016,
  title = {Learning from Imbalanced Data: Open Challenges and Future Directions},
  shorttitle = {Learning from Imbalanced Data},
  author = {Krawczyk, Bartosz},
  date = {2016-11},
  journaltitle = {Progress in Artificial Intelligence},
  shortjournal = {Prog Artif Intell},
  volume = {5},
  number = {4},
  pages = {221--232},
  issn = {2192-6352, 2192-6360},
  doi = {10.1007/s13748-016-0094-0},
  url = {http://link.springer.com/10.1007/s13748-016-0094-0},
  urldate = {2023-02-08},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\krawczykLearningImbalancedData2016.pdf}
}

@article{lahmiri2018,
  title = {Performance of Machine Learning Methods in Diagnosing {{Parkinson}}’s Disease Based on Dysphonia Measures},
  author = {Lahmiri, Salim and Dawson, Debra Ann and Shmuel, Amir},
  date = {2018-02},
  journaltitle = {Biomedical Engineering Letters},
  shortjournal = {Biomed. Eng. Lett.},
  volume = {8},
  number = {1},
  pages = {29--39},
  issn = {2093-9868, 2093-985X},
  doi = {10.1007/s13534-017-0051-2},
  url = {http://link.springer.com/10.1007/s13534-017-0051-2},
  urldate = {2022-01-24},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\lahmiriPerformanceMachineLearning2018.pdf}
}

@article{laplane2019,
  title = {Towards a Classification of Stem Cells},
  author = {Laplane, Lucie and Solary, Eric},
  date = {2019-03-13},
  journaltitle = {eLife},
  volume = {8},
  pages = {e46563},
  issn = {2050-084X},
  doi = {10.7554/eLife.46563},
  url = {https://elifesciences.org/articles/46563},
  urldate = {2022-01-21},
  abstract = {The characteristic properties of stem cells – notably their ability to self-renew and to differentiate – have meant that they have traditionally been viewed as distinct from most other types of cells. However, recent research has blurred the line between stem cells and other cells by showing that the former display a range of behaviors in different tissues and at different stages of development. Here, we use the tools of metaphysics to describe a classification scheme for stem cells, and to highlight what their inherent diversity means for cancer treatment.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\laplaneClassificationStemCells2019.pdf}
}

@incollection{lazaric2012,
  title = {Transfer in {{Reinforcement Learning}}: {{A Framework}} and a {{Survey}}},
  shorttitle = {Transfer in {{Reinforcement Learning}}},
  booktitle = {Reinforcement {{Learning}}},
  author = {Lazaric, Alessandro},
  editor = {Wiering, Marco and van Otterlo, Martijn},
  options = {useprefix=true},
  date = {2012},
  series = {Adaptation, {{Learning}}, and {{Optimization}}},
  volume = {12},
  pages = {143--173},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-27645-3_5},
  url = {http://link.springer.com/10.1007/978-3-642-27645-3_5},
  urldate = {2023-01-31},
  isbn = {978-3-642-27644-6 978-3-642-27645-3},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\lazaricTransferReinforcementLearning2012.pdf}
}

@article{lecunMNISTHandwrittenDigit2010,
  title = {{{MNIST}} Handwritten Digit Database},
  author = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
  date = {2010},
  journaltitle = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume = {2}
}

@article{li2007,
  title = {Identification of {{Pancreatic Cancer Stem Cells}}},
  author = {Li, Chenwei and Heidt, David G. and Dalerba, Piero and Burant, Charles F. and Zhang, Lanjing and Adsay, Volkan and Wicha, Max and Clarke, Michael F. and Simeone, Diane M.},
  date = {2007-02-01},
  journaltitle = {Cancer Research},
  shortjournal = {Cancer Res},
  volume = {67},
  number = {3},
  pages = {1030--1037},
  issn = {0008-5472, 1538-7445},
  doi = {10.1158/0008-5472.CAN-06-2030},
  url = {http://cancerres.aacrjournals.org/lookup/doi/10.1158/0008-5472.CAN-06-2030},
  urldate = {2022-01-25},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\liIdentificationPancreaticCancer2007.pdf}
}

@unpublished{li2021,
  title = {A {{Systematic Collection}} of {{Medical Image Datasets}} for {{Deep Learning}}},
  author = {Li, Johann and Zhu, Guangming and Hua, Cong and Feng, Mingtao and BasheerBennamoun and Li, Ping and Lu, Xiaoyuan and Song, Juan and Shen, Peiyi and Xu, Xu and Mei, Lin and Zhang, Liang and Shah, Syed Afaq Ali and Bennamoun, Mohammed},
  date = {2021-06-24},
  eprint = {2106.12864},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2106.12864},
  urldate = {2022-02-08},
  abstract = {The astounding success made by artificial intelligence (AI) in healthcare and other fields proves that AI can achieve human-like performance. However, success always comes with challenges. Deep learning algorithms are data-dependent and require large datasets for training. The lack of data in the medical imaging field creates a bottleneck for the application of deep learning to medical image analysis. Medical image acquisition, annotation, and analysis are costly, and their usage is constrained by ethical restrictions. They also require many resources, such as human expertise and funding. That makes it difficult for non-medical researchers to have access to useful and large medical data. Thus, as comprehensive as possible, this paper provides a collection of medical image datasets with their associated challenges for deep learning research. We have collected information of around three hundred datasets and challenges mainly reported between 2013 and 2020 and categorized them into four categories: head \& neck, chest \& abdomen, pathology \& blood, and ``others''. Our paper has three purposes: 1) to provide a most up to date and complete list that can be used as a universal reference to easily find the datasets for clinical image analysis, 2) to guide researchers on the methodology to test and evaluate their methods' performance and robustness on relevant datasets, 3) to provide a ``route'' to relevant algorithms for the relevant medical topics, and challenge leaderboards.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\liSystematicCollectionMedical2021.pdf;C\:\\Users\\mario\\Zotero\\storage\\MF6I79CS\\2106.html}
}

@article{li2021a,
  title = {Fast and {{Accurate Classification}} of {{Meta-Genomics Long Reads With deSAMBA}}},
  author = {Li, Gaoyang and Liu, Yongzhuang and Li, Deying and Liu, Bo and Li, Junyi and Hu, Yang and Wang, Yadong},
  date = {2021-04-28},
  journaltitle = {Frontiers in Cell and Developmental Biology},
  shortjournal = {Front. Cell Dev. Biol.},
  volume = {9},
  pages = {643645},
  issn = {2296-634X},
  doi = {10.3389/fcell.2021.643645},
  url = {https://www.frontiersin.org/articles/10.3389/fcell.2021.643645/full},
  urldate = {2022-01-21},
  abstract = {There is still a lack of fast and accurate classification tools to identify the taxonomies of noisy long reads, which is a bottleneck to the use of the promising long-read metagenomic sequencing technologies. Herein, we propose de Bruijn graph-based Sparse Approximate Match Block Analyzer (deSAMBA), a tailored long-read classification approach that uses a novel pseudo alignment algorithm based on sparse approximate match block (SAMB). Benchmarks on real sequencing datasets demonstrate that deSAMBA enables to achieve high yields and fast speed simultaneously, which outperforms state-of-the-art tools and has many potentials to cutting-edge metagenomics studies.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\liFastAccurateClassification2021.pdf}
}

@article{lian2020,
  title = {Artificial-Cell-Type Aware Cell-Type Classification in {{CITE-seq}}},
  author = {Lian, Qiuyu and Xin, Hongyi and Ma, Jianzhu and Konnikova, Liza and Chen, Wei and Gu, Jin and Chen, Kong},
  date = {2020-07-01},
  journaltitle = {Bioinformatics},
  volume = {36},
  pages = {i542-i550},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btaa467},
  url = {https://academic.oup.com/bioinformatics/article/36/Supplement_1/i542/5870491},
  urldate = {2022-01-21},
  abstract = {Motivation: Cellular Indexing of Transcriptomes and Epitopes by sequencing (CITE-seq), couples the measurement of surface marker proteins with simultaneous sequencing of mRNA at single cell level, which brings accurate cell surface phenotyping to single-cell transcriptomics. Unfortunately, multiplets in CITE-seq datasets create artificial cell types (ACT) and complicate the automation of cell surface phenotyping.},
  issue = {Supplement\_1},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\lianArtificialcelltypeAwareCelltype2020.pdf}
}

@article{linFocalLossDense2017,
  title = {Focal {{Loss}} for {{Dense Object Detection}}},
  author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  date = {2017},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1708.02002},
  url = {https://arxiv.org/abs/1708.02002},
  urldate = {2023-02-08},
  abstract = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.},
  version = {2},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences}
}

@article{liu2020,
  title = {Deep {{Learning}} for {{Generic Object Detection}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Generic Object Detection}}},
  author = {Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietikäinen, Matti},
  date = {2020-02},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {128},
  number = {2},
  pages = {261--318},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-019-01247-4},
  url = {https://link.springer.com/10.1007/s11263-019-01247-4},
  urldate = {2022-02-05},
  abstract = {Abstract             Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\liuDeepLearningGeneric2020.pdf}
}

@article{makenaCancerStemCells2020,
  title = {Cancer Stem Cells: {{Road}} to Therapeutic Resistance and Strategies to Overcome Resistance},
  shorttitle = {Cancer Stem Cells},
  author = {Makena, Monish Ram and Ranjan, Alok and Thirumala, Vani and Reddy, Arubala P},
  date = {2020-04},
  journaltitle = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
  shortjournal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
  volume = {1866},
  number = {4},
  pages = {165339},
  issn = {09254439},
  doi = {10.1016/j.bbadis.2018.11.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925443918304769},
  urldate = {2022-01-26},
  langid = {english}
}

@article{mauer2021,
  title = {Automated Age Estimation of Young Individuals Based on {{3D}} Knee {{MRI}} Using Deep Learning},
  author = {der Mauer, Markus Auf and Well, Eilin Jopp-van and Herrmann, Jochen and Groth, Michael and Morlock, Michael M. and Maas, Rainer and Säring, Dennis},
  date = {2021-03},
  journaltitle = {International Journal of Legal Medicine},
  shortjournal = {Int J Legal Med},
  volume = {135},
  number = {2},
  pages = {649--663},
  issn = {0937-9827, 1437-1596},
  doi = {10.1007/s00414-020-02465-z},
  url = {http://link.springer.com/10.1007/s00414-020-02465-z},
  urldate = {2022-02-16},
  abstract = {Abstract             Age estimation is a crucial element of forensic medicine to assess the chronological age of living individuals without or lacking valid legal documentation. Methods used in practice are labor-intensive, subjective, and frequently comprise radiation exposure. Recently, also non-invasive methods using magnetic resonance imaging (MRI) have evaluated and confirmed a correlation between growth plate ossification in long bones and the chronological age of young subjects. However, automated and user-independent approaches are required to perform reliable assessments on large datasets. The aim of this study was to develop a fully automated and computer-based method for age estimation based on 3D knee MRIs using machine learning. The proposed solution is based on three parts: image-preprocessing, bone segmentation, and age estimation. A total of 185 coronal and 404 sagittal MR volumes from Caucasian male subjects in the age range of 13 and 21 years were available. The best result of the fivefold cross-validation was a mean absolute error of 0.67 ± 0.49 years in age regression and an accuracy of 90.9\%, a sensitivity of 88.6\%, and a specificity of 94.2\% in classification (18-year age limit) using a combination of convolutional neural networks and tree-based machine learning algorithms. The potential of deep learning for age estimation is reflected in the results and can be further improved if it is trained on even larger and more diverse datasets.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\mauerAutomatedAgeEstimation2021.pdf}
}

@inproceedings{mikolajczykDataAugmentationImproving2018,
  title = {Data Augmentation for Improving Deep Learning in Image Classification Problem},
  booktitle = {2018 {{International Interdisciplinary PhD Workshop}} ({{IIPhDW}})},
  author = {Mikolajczyk, Agnieszka and Grochowski, Michal},
  date = {2018-05},
  pages = {117--122},
  publisher = {{IEEE}},
  location = {{Swinoujście}},
  doi = {10.1109/IIPHDW.2018.8388338},
  url = {https://ieeexplore.ieee.org/document/8388338/},
  urldate = {2022-02-09},
  eventtitle = {2018 {{International Interdisciplinary PhD Workshop}} ({{IIPhDW}})},
  isbn = {978-1-5386-6143-7}
}

@article{molgaNeuralNetworksModelling2000,
  title = {Neural Networks for Modelling of Chemical Reaction Systems with Complex Kinetics: Oxidation of 2-Octanol with Nitric Acid},
  shorttitle = {Neural Networks for Modelling of Chemical Reaction Systems with Complex Kinetics},
  author = {Molga, E.J. and van Woezik, B.A.A. and Westerterp, K.R.},
  options = {useprefix=true},
  date = {2000-07},
  journaltitle = {Chemical Engineering and Processing: Process Intensification},
  shortjournal = {Chemical Engineering and Processing: Process Intensification},
  volume = {39},
  number = {4},
  pages = {323--334},
  issn = {02552701},
  doi = {10.1016/S0255-2701(99)00093-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0255270199000938},
  urldate = {2022-02-04},
  langid = {english}
}

@online{Monoklonalitaet,
  title = {Monoklonalität},
  url = {https://www.moleculardevices.com/applications/monoclonality},
  urldate = {2022-01-21},
  abstract = {Der Begriff „Monoklonalität“ beschreibt eine Zelllinie, die aus einer einzigen Vorläuferzelle (Einzelzelle) hervorgeht. Sie stellt eine regulatorische Vorschrift für therapeutische Zelllinien dar.},
  langid = {ngerman},
  organization = {{Molecular Devices}},
  file = {C\:\\Users\\mario\\Zotero\\storage\\TAKHTZ2K\\monoclonality.html}
}

@article{narvekarLearningCurriculumPolicies2018,
  title = {Learning {{Curriculum Policies}} for {{Reinforcement Learning}}},
  author = {Narvekar, Sanmit and Stone, Peter},
  date = {2018},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1812.00285},
  url = {https://arxiv.org/abs/1812.00285},
  urldate = {2023-01-25},
  abstract = {Curriculum learning in reinforcement learning is a training methodology that seeks to speed up learning of a difficult target task, by first training on a series of simpler tasks and transferring the knowledge acquired to the target task. Automatically choosing a sequence of such tasks (i.e. a curriculum) is an open problem that has been the subject of much recent work in this area. In this paper, we build upon a recent method for curriculum design, which formulates the curriculum sequencing problem as a Markov Decision Process. We extend this model to handle multiple transfer learning algorithms, and show for the first time that a curriculum policy over this MDP can be learned from experience. We explore various representations that make this possible, and evaluate our approach by learning curriculum policies for multiple agents in two different domains. The results show that our method produces curricula that can train agents to perform on a target task as fast or faster than existing methods.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@article{ngo2017,
  title = {Combining Deep Learning and Level Set for the Automated Segmentation of the Left Ventricle of the Heart from Cardiac Cine Magnetic Resonance},
  author = {Ngo, Tuan Anh and Lu, Zhi and Carneiro, Gustavo},
  date = {2017-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {35},
  pages = {159--171},
  issn = {13618415},
  doi = {10.1016/j.media.2016.05.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S136184151630038X},
  urldate = {2022-01-21},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\ngoCombiningDeepLearning2017.pdf}
}

@article{nguyen2016,
  title = {Stiffness of Pancreatic Cancer Cells Is Associated with Increased Invasive Potential},
  author = {Nguyen, Angelyn V. and Nyberg, Kendra D. and Scott, Michael B. and Welsh, Alia M. and Nguyen, Andrew H. and Wu, Nanping and Hohlbauch, Sophia V. and Geisse, Nicholas A. and Gibb, Ewan A. and Robertson, A. Gordon and Donahue, Timothy R. and Rowat, Amy C.},
  date = {2016},
  journaltitle = {Integrative Biology},
  shortjournal = {Integr. Biol.},
  volume = {8},
  number = {12},
  pages = {1232--1245},
  issn = {1757-9694, 1757-9708},
  doi = {10.1039/C6IB00135A},
  url = {https://academic.oup.com/ib/article/8/12/1232-1245/5115325},
  urldate = {2022-02-01},
  abstract = {This work determines the invasive potential of pancreatic cancer cells, and its relationship to deformability using three independent mechanotyping methods.           ,              Metastasis is a fundamentally physical process in which cells are required to deform through narrow gaps as they invade surrounding tissues and transit to distant sites. In many cancers, more invasive cells are more deformable than less invasive cells, but the extent to which mechanical phenotype, or mechanotype, can predict disease aggressiveness in pancreatic ductal adenocarcinoma (PDAC) remains unclear. Here we investigate the invasive potential and mechanical properties of immortalized PDAC cell lines derived from primary tumors and a secondary metastatic site, as well as noncancerous pancreatic ductal cells. To investigate how invasive behavior is associated with cell mechanotype, we flow cells through micron-scale pores using parallel microfiltration and microfluidic deformability cytometry; these results show that the ability of PDAC cells to passively transit through pores is only weakly correlated with their invasive potential. We also measure the Young's modulus of pancreatic ductal cells using atomic force microscopy, which reveals that there is a strong association between cell stiffness and invasive potential in PDAC cells. To determine the molecular origins of the variability in mechanotype across our PDAC cell lines, we analyze RNAseq data for genes that are known to regulate cell mechanotype. Our results show that vimentin, actin, and lamin A are among the most differentially expressed mechanoregulating genes across our panel of PDAC cell lines, as well as a cohort of 38 additional PDAC cell lines. We confirm levels of these proteins across our cell panel using immunoblotting, and find that levels of lamin A increase with both invasive potential and Young's modulus. Taken together, we find that stiffer PDAC cells are more invasive than more compliant cells, which challenges the paradigm that decreased cell stiffness is a hallmark of metastatic potential.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\nguyenStiffnessPancreaticCancer2016.pdf}
}

@article{ozaki2019,
  title = {Label-Free Classification of Cells Based on Supervised Machine Learning of Subcellular Structures},
  author = {Ozaki, Yusuke and Yamada, Hidenao and Kikuchi, Hirotoshi and Hirotsu, Amane and Murakami, Tomohiro and Matsumoto, Tomohiro and Kawabata, Toshiki and Hiramatsu, Yoshihiro and Kamiya, Kinji and Yamauchi, Toyohiko and Goto, Kentaro and Ueda, Yukio and Okazaki, Shigetoshi and Kitagawa, Masatoshi and Takeuchi, Hiroya and Konno, Hiroyuki},
  editor = {Mumtaz, Wajid},
  date = {2019-01-29},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {14},
  number = {1},
  pages = {e0211347},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0211347},
  url = {https://dx.plos.org/10.1371/journal.pone.0211347},
  urldate = {2022-01-21},
  abstract = {It is demonstrated that cells can be classified by pattern recognition of the subcellular structure of non-stained live cells, and the pattern recognition was performed by machine learning. Human white blood cells and five types of cancer cell lines were imaged by quantitative phase microscopy, which provides morphological information without staining quantitatively in terms of optical thickness of cells. Subcellular features were then extracted from the obtained images as training data sets for the machine learning. The built classifier successfully classified WBCs from cell lines (area under ROC curve = 0.996). This label-free, noncytotoxic cell classification based on the subcellular structure of QPM images has the potential to serve as an automated diagnosis of single cells.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\ozakiLabelfreeClassificationCells2019.pdf}
}

@article{padi2020,
  title = {Comparison of {{Artificial Intelligence}} Based Approaches to Cell Function Prediction},
  author = {Padi, Sarala and Manescu, Petru and Schaub, Nicholas and Hotaling, Nathan and Simon, Carl and Bharti, Kapil and Bajcsy, Peter},
  date = {2020},
  journaltitle = {Informatics in Medicine Unlocked},
  shortjournal = {Informatics in Medicine Unlocked},
  volume = {18},
  pages = {100270},
  issn = {23529148},
  doi = {10.1016/j.imu.2019.100270},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352914819303235},
  urldate = {2022-01-24},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\padiComparisonArtificialIntelligence2020.pdf}
}

@article{pliner2019,
  title = {Supervised Classification Enables Rapid Annotation of Cell Atlases},
  author = {Pliner, Hannah A. and Shendure, Jay and Trapnell, Cole},
  date = {2019-10},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {16},
  number = {10},
  pages = {983--986},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/s41592-019-0535-3},
  url = {http://www.nature.com/articles/s41592-019-0535-3},
  urldate = {2022-01-21},
  abstract = {Single cell molecular profiling technologies are gaining rapid traction, but the manual process by which resulting cell types are typically annotated is labor-intensive and rate-limiting. We describe Garnett, an algorithm and accompanying software for rapidly annotating cell types in scRNA-seq and scATAC-seq datasets, based on an interpretable, hierarchical markup language of cell typespecific genes. Garnett successfully classifies cell types in tissue and whole organism datasets, as well as across species.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\plinerSupervisedClassificationEnables2019.pdf}
}

@article{rahmani2021,
  title = {Machine {{Learning}} ({{ML}}) in {{Medicine}}: {{Review}}, {{Applications}}, and {{Challenges}}},
  shorttitle = {Machine {{Learning}} ({{ML}}) in {{Medicine}}},
  author = {Rahmani, Amir Masoud and Yousefpoor, Efat and Yousefpoor, Mohammad Sadegh and Mehmood, Zahid and Haider, Amir and Hosseinzadeh, Mehdi and Ali Naqvi, Rizwan},
  date = {2021-11-21},
  journaltitle = {Mathematics},
  shortjournal = {Mathematics},
  volume = {9},
  number = {22},
  pages = {2970},
  issn = {2227-7390},
  doi = {10.3390/math9222970},
  url = {https://www.mdpi.com/2227-7390/9/22/2970},
  urldate = {2022-02-01},
  abstract = {Today, artificial intelligence (AI) and machine learning (ML) have dramatically advanced in various industries, especially medicine. AI describes computational programs that mimic and simulate human intelligence, for example, a person’s behavior in solving problems or his ability for learning. Furthermore, ML is a subset of artificial intelligence. It extracts patterns from raw data automatically. The purpose of this paper is to help researchers gain a proper understanding of machine learning and its applications in healthcare. In this paper, we first present a classification of machine learning-based schemes in healthcare. According to our proposed taxonomy, machine learning-based schemes in healthcare are categorized based on data pre-processing methods (data cleaning methods, data reduction methods), learning methods (unsupervised learning, supervised learning, semi-supervised learning, and reinforcement learning), evaluation methods (simulation-based evaluation and practical implementation-based evaluation in real environment) and applications (diagnosis, treatment). According to our proposed classification, we review some studies presented in machine learning applications for healthcare. We believe that this review paper helps researchers to familiarize themselves with the newest research on ML applications in medicine, recognize their challenges and limitations in this area, and identify future research directions.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\rahmaniMachineLearningML2021.pdf}
}

@article{rawatDeepConvolutionalNeural2017,
  title = {Deep {{Convolutional Neural Networks}} for {{Image Classification}}: {{A Comprehensive Review}}},
  shorttitle = {Deep {{Convolutional Neural Networks}} for {{Image Classification}}},
  author = {Rawat, Waseem and Wang, Zenghui},
  date = {2017-09},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {29},
  number = {9},
  pages = {2352--2449},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_00990},
  url = {https://direct.mit.edu/neco/article/29/9/2352-2449/8292},
  urldate = {2022-02-03},
  abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
  langid = {english}
}

@unpublished{redmon2016,
  title = {You {{Only Look Once}}: {{Unified}}, {{Real-Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  date = {2016-05-09},
  eprint = {1506.02640},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1506.02640},
  urldate = {2022-02-08},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\redmonYouOnlyLook2016.pdf;C\:\\Users\\mario\\Zotero\\storage\\88Z5AFKK\\1506.html}
}

@article{rodriguezgaldonClusterAnalysisArtificial2010,
  title = {Cluster {{Analysis}} and {{Artificial Neural Networks Multivariate Classification}} of {{Onion Varieties}}},
  author = {Rodríguez Galdón, Beatriz and Peña-Méndez, Eladia and Havel, Josef and Rodríguez Rodríguez, Elena María and Díaz Romero, Carlos},
  date = {2010-11-10},
  journaltitle = {Journal of Agricultural and Food Chemistry},
  shortjournal = {J. Agric. Food Chem.},
  volume = {58},
  number = {21},
  pages = {11435--11440},
  issn = {0021-8561, 1520-5118},
  doi = {10.1021/jf102014j},
  url = {https://pubs.acs.org/doi/10.1021/jf102014j},
  urldate = {2022-02-04},
  langid = {english}
}

@unpublished{ronneberger2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  date = {2015-05-18},
  eprint = {1505.04597},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1505.04597},
  urldate = {2022-02-10},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\ronnebergerUNetConvolutionalNetworks2015.pdf;C\:\\Users\\mario\\Zotero\\storage\\N7A7K7ZS\\1505.html}
}

@article{rueden2017,
  title = {{{ImageJ2}}: {{ImageJ}} for the next Generation of Scientific Image Data},
  shorttitle = {{{ImageJ2}}},
  author = {Rueden, Curtis T. and Schindelin, Johannes and Hiner, Mark C. and DeZonia, Barry E. and Walter, Alison E. and Arena, Ellen T. and Eliceiri, Kevin W.},
  date = {2017-12},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {18},
  number = {1},
  pages = {529},
  issn = {1471-2105},
  doi = {10.1186/s12859-017-1934-z},
  url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1934-z},
  urldate = {2022-02-01},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\ruedenImageJ2ImageJNext2017.pdf}
}

@article{samuel2000,
  title = {Some Studies in Machine Learning Using the Game of Checkers},
  author = {Samuel, A. L.},
  date = {2000-01},
  journaltitle = {IBM Journal of Research and Development},
  shortjournal = {IBM J. Res. \& Dev.},
  volume = {44},
  number = {1.2},
  pages = {206--226},
  issn = {0018-8646, 0018-8646},
  doi = {10.1147/rd.441.0206},
  url = {http://ieeexplore.ieee.org/document/5389202/},
  urldate = {2022-01-24},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\samuelStudiesMachineLearning2000.pdf}
}

@article{schindelin2012,
  title = {Fiji: An Open-Source Platform for Biological-Image Analysis},
  shorttitle = {Fiji},
  author = {Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
  date = {2012-07},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {9},
  number = {7},
  pages = {676--682},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.2019},
  url = {http://www.nature.com/articles/nmeth.2019},
  urldate = {2022-01-31},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\schindelinFijiOpensourcePlatform2012.pdf}
}

@misc{schulman2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  date = {2017-08-28},
  number = {arXiv:1707.06347},
  eprint = {1707.06347},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1707.06347},
  urldate = {2023-01-25},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\schulmanProximalPolicyOptimization2017.pdf;C\:\\Users\\mario\\Zotero\\storage\\KRDG93H7\\1707.html}
}

@article{schulmanHighDimensionalContinuousControl2015,
  title = {High-{{Dimensional Continuous Control Using Generalized Advantage Estimation}}},
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  date = {2015},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1506.02438},
  url = {https://arxiv.org/abs/1506.02438},
  urldate = {2023-02-06},
  abstract = {Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time.},
  version = {6},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering; electronic engineering; information engineering,Machine Learning (cs.LG),Robotics (cs.RO),Systems and Control (eess.SY)}
}

@article{schwendy,
  title = {Image {{Segmentation}} in {{Microscopic Single Cell Analysis}}},
  author = {Schwendy, Mischa Dominik},
  pages = {113},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\schwendyImageSegmentationMicroscopic.pdf}
}

@article{shen2017,
  title = {Deep {{Learning}} in {{Medical Image Analysis}}},
  author = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
  date = {2017-06-21},
  journaltitle = {Annual Review of Biomedical Engineering},
  shortjournal = {Annu. Rev. Biomed. Eng.},
  volume = {19},
  number = {1},
  pages = {221--248},
  issn = {1523-9829, 1545-4274},
  doi = {10.1146/annurev-bioeng-071516-044442},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-bioeng-071516-044442},
  urldate = {2022-02-03},
  abstract = {This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\shenDeepLearningMedical2017.pdf}
}

@article{smith2019,
  title = {Use of an Imaging Station for Rapid Colony Counting in Radiobiology Studies},
  author = {Smith, Tim A.D. and Cabello, Gema and Mingarelli, Marco},
  date = {2019-10},
  journaltitle = {Applied Radiation and Isotopes},
  shortjournal = {Applied Radiation and Isotopes},
  volume = {152},
  pages = {106--108},
  issn = {09698043},
  doi = {10.1016/j.apradiso.2019.06.028},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0969804319301009},
  urldate = {2022-01-21},
  abstract = {Colony counting by eye is time consuming and subjective. Here comparison between the measurements of proliferative growth inhibition in plates of radiationtreated cells by an imaging station correlated highly significantly with counts determined by eye. This would suggest that an imaging station could be a viable alternative for colony counting for doses over 200KBq.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\smithUseImagingStation2019.pdf}
}

@article{songObservationalOverfittingReinforcement2019,
  title = {Observational {{Overfitting}} in {{Reinforcement Learning}}},
  author = {Song, Xingyou and Jiang, Yiding and Tu, Stephen and Du, Yilun and Neyshabur, Behnam},
  date = {2019},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1912.02975},
  url = {https://arxiv.org/abs/1912.02975},
  urldate = {2023-01-31},
  abstract = {A major component of overfitting in model-free reinforcement learning (RL) involves the case where the agent may mistakenly correlate reward with certain spurious features from the observations generated by the Markov Decision Process (MDP). We provide a general framework for analyzing this scenario, which we use to design multiple synthetic benchmarks from only modifying the observation space of an MDP. When an agent overfits to different observation spaces even if the underlying MDP dynamics is fixed, we term this observational overfitting. Our experiments expose intriguing properties especially with regards to implicit regularization, and also corroborate results from previous works in RL generalization and supervised learning (SL).},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@article{srivastavaDropoutSimpleWay2014,
  title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  date = {2014},
  journaltitle = {The journal of machine learning research},
  volume = {15},
  number = {1},
  pages = {1929--1958},
  publisher = {{JMLR. org}}
}

@article{su2020,
  title = {Automatic {{Detection Method}} for {{Cancer Cell Nucleus Image Based}} on {{Deep-Learning Analysis}} and {{Color Layer Signature Analysis Algorithm}}},
  author = {Su, Hsing-Hao and Pan, Hung-Wei and Lu, Chuan-Pin and Chuang, Jyun-Jie and Yang, Tsan},
  date = {2020-08-07},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {20},
  number = {16},
  pages = {4409},
  issn = {1424-8220},
  doi = {10.3390/s20164409},
  url = {https://www.mdpi.com/1424-8220/20/16/4409},
  urldate = {2022-01-21},
  abstract = {Exploring strategies to treat cancer has always been an aim of medical researchers. One of the available strategies is to use targeted therapy drugs to make the chromosomes in cancer cells unstable such that cell death can be induced, and the elimination of highly proliferative cancer cells can be achieved. Studies have reported that the mitotic defects and micronuclei in cancer cells can be used as biomarkers to evaluate the instability of the chromosomes. Researchers use these two biomarkers to assess the effects of drugs on eliminating cancer cells. However, manual work is required to count the number of cells exhibiting mitotic defects and micronuclei either directly from the viewing window of a microscope or from an image, which is tedious and creates errors. Therefore, this study aims to detect cells with mitotic defects and micronuclei by applying an approach that can automatically count the targets. This approach integrates the application of a convolutional neural network for normal cell identification and the proposed color layer signature analysis (CLSA) to spot cells with mitotic defects and micronuclei. This approach provides a method for researchers to detect colon cancer cells in an accurate and time-efficient manner, thereby decreasing errors and the processing time. The following sections will illustrate the methodology and workflow design of this study, as well as explain the practicality of the experimental comparisons and the results that were used to validate the practicality of this algorithm.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\suAutomaticDetectionMethod2020.pdf}
}

@article{sutton1992,
  title = {Introduction: {{The}} Challenge of Reinforcement Learning},
  shorttitle = {Introduction},
  author = {Sutton, Richard S.},
  date = {1992-05},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {8},
  number = {3-4},
  pages = {225--227},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/BF00992695},
  url = {http://link.springer.com/10.1007/BF00992695},
  urldate = {2023-01-31},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\suttonIntroductionChallengeReinforcement1992.pdf}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  date = {2018},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  pagetotal = {526},
  keywords = {Reinforcement learning}
}

@incollection{tamilselvan2018,
  title = {Image {{Segmentation}}},
  booktitle = {Medical and {{Biological Image Analysis}}},
  author = {Tamilselvan, Kumaravel Subramaniam and Murugesan, Govindasamy},
  editor = {Koprowski, Robert},
  date = {2018-07-04},
  publisher = {{InTech}},
  doi = {10.5772/intechopen.76428},
  url = {http://www.intechopen.com/books/medical-and-biological-image-analysis/image-segmentation},
  urldate = {2022-01-31},
  isbn = {978-1-78923-330-8 978-1-78923-331-5},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\tamilselvanImageSegmentation2018.pdf}
}

@article{tan2011,
  title = {Holoclone {{Forming Cells}} from {{Pancreatic Cancer Cells Enrich Tumor Initiating Cells}} and {{Represent}} a {{Novel Model}} for {{Study}} of {{Cancer Stem Cells}}},
  author = {Tan, Lei and Sui, Xin and Deng, Hongkui and Ding, Mingxiao},
  editor = {Algül, Hana},
  date = {2011-08-03},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS ONE},
  volume = {6},
  number = {8},
  pages = {e23383},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0023383},
  url = {https://dx.plos.org/10.1371/journal.pone.0023383},
  urldate = {2022-01-25},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\tanHolocloneFormingCells2011.pdf}
}

@article{timjonesMachineLearningBias2019,
  title = {Machine Learning and Bias},
  author = {Tim Jones, M.},
  date = {2019-08-26},
  journaltitle = {IBM Journal of Research and Development},
  url = {https://developer.ibm.com/articles/machine-learning-and-bias/},
  urldate = {2023-01-18},
  entrysubtype = {magazine},
  langid = {english}
}

@article{tuAdvantagesDisadvantagesUsing1996,
  title = {Advantages and Disadvantages of Using Artificial Neural Networks versus Logistic Regression for Predicting Medical Outcomes},
  author = {Tu, Jack V.},
  date = {1996-11},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {49},
  number = {11},
  pages = {1225--1231},
  issn = {08954356},
  doi = {10.1016/S0895-4356(96)00002-9},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435696000029},
  urldate = {2022-02-04},
  langid = {english}
}

@inproceedings{wallaceClassImbalanceRedux2011,
  title = {Class {{Imbalance}}, {{Redux}}},
  booktitle = {2011 {{IEEE}} 11th {{International Conference}} on {{Data Mining}}},
  author = {Wallace, Byron C. and Small, Kevin and Brodley, Carla E. and Trikalinos, Thomas A.},
  date = {2011-12},
  pages = {754--763},
  publisher = {{IEEE}},
  location = {{Vancouver, BC, Canada}},
  doi = {10.1109/ICDM.2011.33},
  url = {http://ieeexplore.ieee.org/document/6137280/},
  urldate = {2023-02-08},
  eventtitle = {2011 {{IEEE}} 11th {{International Conference}} on {{Data Mining}} ({{ICDM}})},
  isbn = {978-1-4577-2075-8 978-0-7695-4408-3}
}

@article{wang2020,
  title = {An Artificial Intelligent Platform for Live Cell Identification and the Detection of Cross-Contamination},
  author = {Wang, Ruixin and Wang, Dongni and Kang, Dekai and Guo, Xusen and Guo, Chong and Dongye, Meimei and Zhu, Yi and Chen, Chuan and Zhang, Xiayin and Long, Erping and Wu, Xiaohang and Liu, Zhenzhen and Lin, Duoru and Wang, Jinghui and Huang, Kai and Lin, Haotian},
  date = {2020-06},
  journaltitle = {Annals of Translational Medicine},
  shortjournal = {Ann Transl Med},
  volume = {8},
  number = {11},
  pages = {697--697},
  issn = {23055839, 23055847},
  doi = {10.21037/atm.2019.07.105},
  url = {http://atm.amegroups.com/article/view/29872/html},
  urldate = {2022-01-21},
  abstract = {Background: About 30\% of cell lines have been cellular cross-contaminated and misidentification, which can result in invalidated experimental results and unusable therapeutic products. Cell morphology under the microscope was observed routinely, and further DNA sequencing analysis was performed periodically to verify cell line identity, but the sequencing analysis was costly, time-consuming, and labor intensive. The purpose of this study was to construct a novel artificial intelligence (AI) technology for “cell face” recognition, in which can predict DNA-level identification labels only using cell images. Methods: Seven commonly used cell lines were cultured and co-cultured in pairs (totally 8 categories) to simulated the situation of pure and cross-contaminated cells. The microscopy images were obtained and labeled of cell types by the result of short tandem repeat profiling. About 2 million patch images were used for model training and testing. AlexNet was used to demonstrate the effectiveness of convolutional neural network (CNN) in cell classification. To further improve the feasibility of detecting cross-contamination, the bilinear network for fine-grained identification was constructed. The specificity, sensitivity, and accuracy of the model were tested separately by external validation. Finally, the cell semantic segmentation was conducted by DilatedNet. Results: The cell texture and density were the influencing factors that can be better recognized by the bilinear convolutional neural network (BCNN) comparing to AlexNet. The BCNN achieved 99.5\% accuracy in identifying seven pure cell lines and 86.3\% accuracy for detecting cross-contamination (mixing two of the seven cell lines). DilatedNet was applied to the semantic segment for analyzing in single-cell level and achieved an accuracy of 98.2\%. Conclusions: The deep CNN model proposed in this study has the ability to recognize small differences in cell morphology, and achieved high classification accuracy.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\wangArtificialIntelligentPlatform2020.pdf}
}

@article{wang2020a,
  title = {Class {{Balanced Loss}} for {{Image Classification}}},
  author = {Wang, Lin and Wang, Chaoli and Sun, Zhanquan and Cheng, Shuqun and Guo, Lei},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {81142--81153},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2991237},
  url = {https://ieeexplore.ieee.org/document/9081913/},
  urldate = {2023-02-08},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\wangClassBalancedLoss2020.pdf}
}

@article{wang2021,
  title = {A Deep Learning Method for Counting White Blood Cells in Bone Marrow Images},
  author = {Wang, Da and Hwang, Maxwell and Jiang, Wei-Cheng and Ding, Kefeng and Chang, Hsiao Chien and Hwang, Kao-Shing},
  date = {2021-11},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {22},
  number = {S5},
  pages = {94},
  issn = {1471-2105},
  doi = {10.1186/s12859-021-04003-z},
  url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04003-z},
  urldate = {2022-01-21},
  abstract = {Background:\hspace{0.6em} Differentiating and counting various types of white blood cells (WBC) in bone marrow smears allows the detection of infection, anemia, and leukemia or analy‑sis of a process of treatment. However, manually locating, identifying, and counting the different classes of WBC is time-consuming and fatiguing. Classification and counting accuracy depends on the capability and experience of operators. Results:\hspace{0.6em} This paper uses a deep learning method to count cells in color bone mar‑row microscopic images automatically. The proposed method uses a Faster RCNN and a Feature Pyramid Network to construct a system that deals with various illumination levels and accounts for color components’ stability. The dataset of The Second Affiliated Hospital of Zhejiang University is used to train and test. Conclusions:\hspace{0.6em} The experiments test the effectiveness of the proposed white blood cell classification system using a total of 609 white blood cell images with a resolution of 2560\,×\,1920. The highest overall correct recognition rate could reach 98.8\% accuracy. The experimental results show that the proposed system is comparable to some stateof-art systems. A user interface allows pathologists to operate the system easily.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\wangDeepLearningMethod2021.pdf}
}

@article{wang2021a,
  title = {Self-Paced and Self-Consistent Co-Training for Semi-Supervised Image Segmentation},
  author = {Wang, Ping and Peng, Jizong and Pedersoli, Marco and Zhou, Yuanfeng and Zhang, Caiming and Desrosiers, Christian},
  date = {2021-10},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {73},
  eprint = {2011.00325},
  eprinttype = {arxiv},
  pages = {102146},
  issn = {13618415},
  doi = {10.1016/j.media.2021.102146},
  url = {http://arxiv.org/abs/2011.00325},
  urldate = {2022-01-21},
  abstract = {Deep co-training has recently been proposed as an effective approach for image segmentation when annotated data is scarce. In this paper, we improve existing approaches for semi-supervised segmentation with a self-paced and self-consistent co-training method. To help distillate information from unlabeled images, we first design a self-paced learning strategy for co-training that lets jointly-trained neural networks focus on easier-to-segment regions first, and then gradually consider harder ones. This is achieved via an end-to-end differentiable loss in the form of a generalized Jensen Shannon Divergence (JSD). Moreover, to encourage predictions from different networks to be both consistent and confident, we enhance this generalized JSD loss with an uncertainty regularizer based on entropy. The robustness of individual models is further improved using a self-ensembling loss that enforces their prediction to be consistent across different training iterations. We demonstrate the potential of our method on three challenging image segmentation problems with different image modalities, using small fraction of labeled data. Results show clear advantages in terms of performance compared to the standard co-training baselines and recently proposed state-of-the-art approaches for semi-supervised segmentation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\wangSelfpacedSelfconsistentCotraining2021.pdf}
}

@inproceedings{wangTrainingDeepNeural2016,
  title = {Training Deep Neural Networks on Imbalanced Data Sets},
  booktitle = {2016 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Wang, Shoujin and Liu, Wei and Wu, Jia and Cao, Longbing and Meng, Qinxue and Kennedy, Paul J.},
  date = {2016-07},
  pages = {4368--4374},
  publisher = {{IEEE}},
  location = {{Vancouver, BC, Canada}},
  doi = {10.1109/IJCNN.2016.7727770},
  url = {http://ieeexplore.ieee.org/document/7727770/},
  urldate = {2022-02-08},
  eventtitle = {2016 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  isbn = {978-1-5090-0620-5}
}

@misc{xiao2017,
  title = {Fashion-{{MNIST}}: A {{Novel Image Dataset}} for {{Benchmarking Machine Learning Algorithms}}},
  shorttitle = {Fashion-{{MNIST}}},
  author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  date = {2017-09-15},
  number = {arXiv:1708.07747},
  eprint = {1708.07747},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1708.07747},
  urldate = {2023-01-18},
  abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\xiaoFashionMNISTNovelImage2017.pdf;C\:\\Users\\mario\\Zotero\\storage\\3VTVHVW5\\1708.html}
}

@article{yamashita2018,
  title = {Convolutional Neural Networks: An Overview and Application in Radiology},
  shorttitle = {Convolutional Neural Networks},
  author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
  date = {2018-08},
  journaltitle = {Insights into Imaging},
  shortjournal = {Insights Imaging},
  volume = {9},
  number = {4},
  pages = {611--629},
  issn = {1869-4101},
  doi = {10.1007/s13244-018-0639-9},
  url = {https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9},
  urldate = {2022-02-02},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\yamashitaConvolutionalNeuralNetworks2018.pdf}
}

@inproceedings{yanComparisonFiveDiscriminant2011,
  title = {The {{Comparison}} of {{Five Discriminant Methods}}},
  booktitle = {2011 {{International Conference}} on {{Management}} and {{Service Science}}},
  author = {Yan, Hu and Dai, Yu},
  date = {2011-08},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Wuhan, China}},
  doi = {10.1109/ICMSS.2011.5999201},
  url = {http://ieeexplore.ieee.org/document/5999201/},
  urldate = {2022-02-01},
  eventtitle = {2011 {{International Conference}} on {{Management}} and {{Service Science}} ({{MASS}} 2011)},
  isbn = {978-1-4244-6579-8}
}

@inproceedings{yanComparisonFiveDiscriminant2011a,
  title = {The {{Comparison}} of {{Five Discriminant Methods}}},
  booktitle = {2011 {{International Conference}} on {{Management}} and {{Service Science}}},
  author = {Yan, Hu and Dai, Yu},
  date = {2011-08},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Wuhan, China}},
  doi = {10.1109/ICMSS.2011.5999201},
  url = {http://ieeexplore.ieee.org/document/5999201/},
  urldate = {2022-02-01},
  eventtitle = {2011 {{International Conference}} on {{Management}} and {{Service Science}} ({{MASS}} 2011)},
  isbn = {978-1-4244-6579-8}
}

@article{yingOverviewOverfittingIts2019,
  title = {An {{Overview}} of {{Overfitting}} and Its {{Solutions}}},
  author = {Ying, Xue},
  date = {2019-02},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  volume = {1168},
  pages = {022022},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/1168/2/022022},
  url = {https://iopscience.iop.org/article/10.1088/1742-6596/1168/2/022022},
  urldate = {2022-02-10}
}

@article{yu2021,
  title = {Automatic {{Classification}} of {{Cervical Cells Using Deep Learning Method}}},
  author = {Yu, Suxiang and Feng, Xinxing and Wang, Bin and Dun, Hua and Zhang, Shuai and Zhang, Ruihong and Huang, Xin},
  date = {2021},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {9},
  pages = {32559--32568},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3060447},
  url = {https://ieeexplore.ieee.org/document/9358146/},
  urldate = {2022-01-21},
  abstract = {Cervical cancer is the fourth most prevalent disease among women. Prompt diagnosis and its management can significantly improve patients’ survival rates. Therefore, routine screening for cervical cancer is of paramount importance. Herein, we explore the potential of a deep learning model to automatically distinguish abnormal cells from normal cells. The ThinPrep cytologic test dataset was collected from the fourth central hospital of Baoding city, China. Based on the dataset, four classification models were developed. The first model was a 10-layer convolutional neural network (CNN). The second model was an advancement of the first model equipped with a spatial pyramid pooling (SPP) layer (CNN + SPP) to treat cell images based on their sizes. Based on the first model, the third model replaced the CNN layers with the inception module (CNN + Inception). However, the fourth model incorporated both the SPP layer and the inception module into the first model (CNN + inception + SPP). The performances of the four models are estimated and compared by using the same testing data and evaluation index. The testing results demonstrated that the fourth model yields the best performance. Moreover, the area under the curve (AUC) for module four was 0.997.},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\yuAutomaticClassificationCervical2021.pdf}
}

@article{zhengEffectsClassImbalance2020,
  title = {The {{Effects}} of {{Class Imbalance}} and {{Training Data Size}} on {{Classifier Learning}}: {{An Empirical Study}}},
  shorttitle = {The {{Effects}} of {{Class Imbalance}} and {{Training Data Size}} on {{Classifier Learning}}},
  author = {Zheng, Wanwan and Jin, Mingzhe},
  date = {2020-03},
  journaltitle = {SN Computer Science},
  shortjournal = {SN COMPUT. SCI.},
  volume = {1},
  number = {2},
  pages = {71},
  issn = {2662-995X, 2661-8907},
  doi = {10.1007/s42979-020-0074-0},
  url = {http://link.springer.com/10.1007/s42979-020-0074-0},
  urldate = {2022-02-08},
  langid = {english}
}

@article{zou2005,
  title = {Regularization and Variable Selection via the Elastic Net},
  author = {Zou, Hui and Hastie, Trevor},
  date = {2005-04},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  shortjournal = {J Royal Statistical Soc B},
  volume = {67},
  number = {2},
  pages = {301--320},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.1467-9868.2005.00503.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x},
  urldate = {2023-01-18},
  langid = {english},
  file = {C\:\\Users\\mario\\Documents\\Master\\master-haw\\PDF\\zouRegularizationVariableSelection2005.pdf}
}
